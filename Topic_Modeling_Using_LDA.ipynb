{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "# LDA는 빈도수에만 기반하는 CountVectorizer 사용함!\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "metadata": {
        "id": "F_CQAf1lvu8G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 주어진 데이터셋의 일부 카테고리 데이터만 추출하므로 카테고리 사전에 설정\n",
        "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
        "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med']\n",
        "\n",
        "# 설정해준 카테고리의 데이터들만 추출\n",
        "news_df = fetch_20newsgroups(subset = 'all', remove = ('headers', 'footers', 'quotes'),\n",
        "                             categories = cats, random_state = 12)"
      ],
      "metadata": {
        "id": "XjhebdvKv1kk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer로 텍스트 데이터를 단어 빈도수에 기반해 벡터화시키기 (fit_transform까지)\n",
        "count_vect = CountVectorizer(max_df = 0.95, max_features = 1000,\n",
        "                             min_df = 2, stop_words = 'english',\n",
        "                             ngram_range = (1, 2))\n",
        "fit_vect = count_vect.fit_transform(news_df.data)"
      ],
      "metadata": {
        "id": "21TfEouNeYWP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LDA 클래스를 이용해서 피쳐 벡터화시킨 것을 토픽 모델링 시키기\n",
        "# 8개의 주제만 뽑았으니 n_components 8로 설정\n",
        "lda = LatentDirichletAllocation(n_components = 8, random_state =42)\n",
        "lda.fit(fit_vect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "V3iIkU5lgFxu",
        "outputId": "40ad12b1-327b-4447-f19d-1b1c82484542"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=8, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=8, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=8, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# components_ 속성은 8개의 토픽별(row)로 1000개의 feature(단어)들의 분포수치(column)를 보여줌\n",
        "print(lda.components_.shape)\n",
        "print(lda.components_)\n",
        "\n",
        "# 행은 각각의 토픽, 열은 단어들을 벡터화시킨 features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yIc_r4Cga1O",
        "outputId": "e50f59a3-6ec6-4bd0-a053-8be9540e1ba2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 1000)\n",
            "[[4.21886779e+01 1.25077441e-01 1.03902744e+01 ... 3.28675046e+01\n",
            "  1.25032926e-01 2.23626159e+00]\n",
            " [3.31601110e+02 1.13269256e+02 1.62846341e+02 ... 1.38787171e-01\n",
            "  2.40125634e+02 3.98253576e+00]\n",
            " [1.27625269e-01 9.96794709e+01 1.25480119e-01 ... 7.24201742e+00\n",
            "  1.90971768e+01 5.07321349e+01]\n",
            " ...\n",
            " [1.25089768e-01 3.89851204e+01 1.25038018e-01 ... 2.14401784e+02\n",
            "  1.25058173e-01 9.50015891e+01]\n",
            " [1.25041718e-01 2.43565827e+02 1.25013778e-01 ... 2.25580117e+01\n",
            "  2.46882968e+01 4.56696629e+01]\n",
            " [1.25067731e-01 1.25058566e-01 1.25000680e-01 ... 1.20416570e+02\n",
            "  1.25047652e-01 3.96898176e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토픽 별로 어떤 단어들이 많이 분포하는지 시각적으로 보기 위한 함수\n",
        "# 이 때 lda_model이란, 벡터화시킨 텍스트 데이터를 fit까지만 적용한 모델\n",
        "def display_topic_words(ida_model, features_names, num_top_words):\n",
        "    for topic_idx, topic in enumerate(ida_model.components_):\n",
        "        print('\\nTopic #', topic_idx + 1)\n",
        "\n",
        "        # Topic 별로 1000개의 단어들(features) 중에서 높은 값 순으로 정렬 후 index를 반환해줌\n",
        "        # argsort()는 디폴트가 오름차순임. 그래서 [::-1]로 내림차순으로 바꿔주기\n",
        "        topic_word_idx = topic.argsort()[::-1]\n",
        "        top_idx = topic_word_idx[:num_top_words]\n",
        "\n",
        "        # CountVectorizer 함수 할당시킨 객체에 get_feature_names()로 벡터화시킨 feature 볼 수 있음\n",
        "        # 이 벡터화시킨 단어들(features)은 숫자-알파벳 순으로 정렬되며, 단어들 순서는 fit_transform 시키고 난 이후에도 동일\n",
        "        feature_concat = '+'.join([str(features_names[i]) + '*' + str(round(topic[i], 1)) for i in top_idx])\n",
        "        print(feature_concat)"
      ],
      "metadata": {
        "id": "ktd-fVNVge9V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = count_vect.get_feature_names_out()\n",
        "display_topic_words(lda, feature_names, 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPwjkOc4iELd",
        "outputId": "decaa8ae-cfd2-452f-bf8d-5f04eede2aaf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic # 1\n",
            "file*1159.4+use*991.4+jpeg*784.4+program*783.8+window*763.5+image*568.2+output*538.4+display*533.8+color*525.8+using*493.1+files*455.3+gif*432.8+bit*400.6+entry*396.9+set*383.0\n",
            "\n",
            "Topic # 2\n",
            "university*372.0+00*331.6+new*317.4+03*266.7+ed*257.8+02*254.4+04*246.6+york*240.1+new york*239.1+ground*205.6+adl*189.1+wire*188.0+circuit*186.1+professor*177.5+san*169.6\n",
            "\n",
            "Topic # 3\n",
            "israel*805.1+israeli*475.8+medical*437.0+10*426.1+research*384.2+health*376.2+1993*346.9+arab*339.3+disease*333.1+cancer*321.1+patients*303.1+12*292.1+use*274.7+number*274.3+april*268.8\n",
            "\n",
            "Topic # 4\n",
            "edu*1584.7+graphics*998.5+available*855.8+software*792.8+com*760.2+ftp*759.8+image*725.9+dos*684.1+data*605.6+version*556.8+pub*553.4+windows*529.2+mail*449.7+server*419.2+computer*418.3\n",
            "\n",
            "Topic # 5\n",
            "know*1067.3+like*857.8+thanks*788.2+does*671.1+just*624.7+don*559.2+bike*540.1+ve*473.8+help*447.9+mail*391.4+edu*389.6+need*383.6+want*371.1+looking*340.4+use*340.4\n",
            "\n",
            "Topic # 6\n",
            "don*1415.4+just*1240.6+like*1077.8+think*1067.9+time*946.5+good*910.1+know*825.3+year*698.0+say*611.6+way*593.7+didn*588.8+really*579.1+better*573.9+going*571.5+right*567.4\n",
            "\n",
            "Topic # 7\n",
            "armenian*1004.1+people*858.1+armenians*826.1+turkish*680.6+said*655.9+jews*453.7+government*428.2+war*421.8+killed*366.5+armenia*356.1+children*343.8+turkey*332.1+muslim*325.1+genocide*320.6+turks*316.0\n",
            "\n",
            "Topic # 8\n",
            "god*2015.2+people*956.8+jesus*690.1+church*662.5+believe*624.4+think*619.4+does*600.8+christ*548.7+say*520.3+christian*483.9+know*446.5+christians*441.4+don*432.3+bible*426.1+did*419.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transform 함수를 호출해서 '문서별(row) 토픽들(columns)의 분포'까지 살필 수 있음\n",
        "doc_topics = lda.transform(fit_vect)\n",
        "print(doc_topics.shape)\n",
        "print(doc_topics[:2])\n",
        "\n",
        "# 행은 각 문서들, 열은 각 토픽들"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZXqlhediI9U",
        "outputId": "ed5d3af2-a623-477b-eec1-79452486e0bf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7862, 8)\n",
            "[[0.41998894 0.00543729 0.00543985 0.00544059 0.00544265 0.54737167\n",
            "  0.00543803 0.00544097]\n",
            " [0.01564771 0.01564216 0.77994069 0.12615745 0.01565929 0.01563803\n",
            "  0.01564152 0.01567315]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# 주어진 내장 텍스트 데이터의 문서 이름에는 카테고리가 labeling되어 있음\n",
        "# 따라서, 카테고리가 무엇인지 아는 상태이니까 어떤 문서들이 어떤 토픽들이 높은지 확인해보자\n",
        "# 그리고 그 토픽들이 각각 무엇을 내용으로 하는지 추측해보자\n",
        "# 주어진 데이터셋의 filename 속성을 이용해서 카테고리 값들 가져오기\n",
        "\n",
        "\n",
        "def get_filename_list(newsdata):\n",
        "    filename_lst = []\n",
        "    for file in newsdata.filenames:\n",
        "        filename_temp = file.split('/')[-2:]\n",
        "        filename = '.'.join(filename_temp)\n",
        "        filename_lst.append(filename)\n",
        "    return filename_lst\n",
        "\n",
        "filename_lst = get_filename_list(news_df)\n"
      ],
      "metadata": {
        "id": "cEAqmuObi6jM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame 형태로 만들어보기\n",
        "topic_names = ['Topic #' + str(i) for i in range(0,8)]\n",
        "topic_df = pd.DataFrame(data = doc_topics, columns = topic_names, index = filename_lst)\n",
        "print(topic_df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBed_4BGjrym",
        "outputId": "5166568a-43d7-43dc-acc1-6092ff289f83"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              Topic #0  Topic #1  Topic #2  Topic #3  \\\n",
            "comp.graphics.38765           0.419989  0.005437  0.005440  0.005441   \n",
            "sci.med.59107                 0.015648  0.015642  0.779941  0.126157   \n",
            "sci.electronics.54182         0.005444  0.005446  0.005440  0.005450   \n",
            "rec.motorcycles.103182        0.007356  0.007360  0.007354  0.007355   \n",
            "soc.religion.christian.21740  0.001739  0.001739  0.001738  0.001738   \n",
            "rec.sport.baseball.105077     0.000568  0.996022  0.000568  0.000568   \n",
            "talk.politics.mideast.75974   0.002274  0.002275  0.385195  0.002275   \n",
            "talk.politics.mideast.76050   0.012513  0.012506  0.012522  0.230723   \n",
            "soc.religion.christian.20900  0.015639  0.015626  0.015631  0.015629   \n",
            "sci.electronics.54334         0.005693  0.005688  0.005696  0.005693   \n",
            "rec.sport.baseball.102625     0.007816  0.007839  0.007833  0.007815   \n",
            "sci.electronics.53888         0.013908  0.013893  0.013901  0.013910   \n",
            "rec.motorcycles.104346        0.125000  0.125000  0.125000  0.125000   \n",
            "soc.religion.christian.21612  0.001025  0.001026  0.343399  0.067753   \n",
            "sci.electronics.53969         0.004634  0.004636  0.004643  0.004631   \n",
            "sci.electronics.53503         0.013913  0.013893  0.013902  0.348745   \n",
            "rec.motorcycles.104518        0.020843  0.020834  0.020844  0.020836   \n",
            "sci.med.59148                 0.009627  0.009616  0.373133  0.009617   \n",
            "sci.med.59044                 0.000840  0.050704  0.813729  0.000840   \n",
            "comp.graphics.38385           0.006587  0.006581  0.006583  0.465195   \n",
            "\n",
            "                              Topic #4  Topic #5  Topic #6  Topic #7  \n",
            "comp.graphics.38765           0.005443  0.547372  0.005438  0.005441  \n",
            "sci.med.59107                 0.015659  0.015638  0.015642  0.015673  \n",
            "sci.electronics.54182         0.005444  0.961889  0.005439  0.005447  \n",
            "rec.motorcycles.103182        0.388904  0.480587  0.007359  0.093724  \n",
            "soc.religion.christian.21740  0.001739  0.001739  0.001737  0.987832  \n",
            "rec.sport.baseball.105077     0.000568  0.000568  0.000568  0.000568  \n",
            "talk.politics.mideast.75974   0.100608  0.202194  0.302901  0.002277  \n",
            "talk.politics.mideast.76050   0.012538  0.477684  0.228995  0.012518  \n",
            "soc.religion.christian.20900  0.015643  0.890545  0.015635  0.015652  \n",
            "sci.electronics.54334         0.752718  0.213133  0.005685  0.005694  \n",
            "rec.sport.baseball.102625     0.007824  0.794708  0.007818  0.158347  \n",
            "sci.electronics.53888         0.902693  0.013901  0.013890  0.013904  \n",
            "rec.motorcycles.104346        0.125000  0.125000  0.125000  0.125000  \n",
            "soc.religion.christian.21612  0.056471  0.001027  0.001026  0.528272  \n",
            "sci.electronics.53969         0.967540  0.004641  0.004636  0.004639  \n",
            "sci.electronics.53503         0.567863  0.013896  0.013890  0.013897  \n",
            "rec.motorcycles.104518        0.853998  0.020872  0.020898  0.020875  \n",
            "sci.med.59148                 0.009627  0.009640  0.009622  0.569119  \n",
            "sci.med.59044                 0.131365  0.000841  0.000840  0.000840  \n",
            "comp.graphics.38385           0.495309  0.006581  0.006581  0.006583  \n"
          ]
        }
      ]
    }
  ]
}